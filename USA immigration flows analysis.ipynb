{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "USA immigration flows analysis\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Scope \n",
    "Analyze how the immigration flows in USA change during the year and how the immigration demographics are distributed <br>\n",
    "\n",
    "Datasets used: \n",
    "- I94 Immigration Data\n",
    "- U.S. City Demographic Data\n",
    "- Airports\n",
    "\n",
    "The data will be gathered in parquet files (if origin data splitted), then cleaned and filtered to remove invalid and unnecessary data and then stored in other parquet files containing fact and dimensions tables.\n",
    "Quality checks will be executed on the data.<br>\n",
    "The final dataset can be used to find the number of immigrants travelling to USA each month for the year 2016, from where, for how long, to where, in which city and similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Describe and Gather Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will use Spark to gather and trasform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create or get the Spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "And this are the datasets that we will use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### I94 Immigration Data\n",
    "This data comes from the US National Tourism and Trade Office. The data comes from [here](https://www.trade.gov/national-travel-and-tourism-office). It includes information about the immigration arrivals and departures from various countries into different US cities with reason for the travel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The dataset contains data of the year 2016 and is stored into <br>\n",
    "`../../data/18-83510-I94-Data-2016/`  <br>\n",
    "divided into different files, let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run this cell to start from a clean environment\n",
    "rm -rf sas_data.parquet\n",
    "rm -rf pipeline_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat\n",
      "/data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat\n"
     ]
    }
   ],
   "source": [
    "# Check how the data is split\n",
    "for path in Path('../../data/18-83510-I94-Data-2016/').rglob('i94_???16_sub.sas7bdat'):\n",
    "    print(path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save the raw data into a signle local parquet for the immigration data\n",
    "for path in Path('../../data/18-83510-I94-Data-2016/').rglob('i94_???16_sub.sas7bdat'):\n",
    "    df_spark = spark.read.format('com.github.saurfang.sas.spark').load(str(path.resolve()))\n",
    "    df_spark.write.mode('append').partitionBy(\"i94mon\").parquet(\"sas_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the immigration data\n",
    "df_immigration = spark.read.parquet(\"sas_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40790529, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset dimensions\n",
    "(df_immigration.count(), len(df_immigration.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### U.S. City Demographic Data\n",
    "This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. More info can be found [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/information/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'us-cities-demographics.csv'\n",
    "df_demographic = spark.read.options(header=True,\n",
    "                        inferSchema=True,\n",
    "                        delimiter=';'\n",
    "                       ).csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_demographic.count(), len(df_demographic.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demographic.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Airports\n",
    "This dataset contains information about the main airports in the world, with city, position and timezone. More info [here](http://www.lsv.fr/~sirangel/teaching/dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'Airports.csv'\n",
    "df_airports = spark.read.options(header=True,\n",
    "                        inferSchema=True,\n",
    "                        delimiter=';',\n",
    "                        escape='\\\\',\n",
    "                       ).csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4246, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_airports.count(), len(df_airports.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- IATA: string (nullable = true)\n",
      " |-- ICAO: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Altitude: string (nullable = true)\n",
      " |-- Timezone: integer (nullable = true)\n",
      " |-- DST: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airports.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "The immigration datasets contains a lot of dirt data, with duplicates and invalid data.\n",
    "These are the cleaning steps\n",
    "\n",
    "#### Cleaning Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Read the Labels description, to remove unwanted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"I94_SAS_Labels_Descriptions_transformed.json\",'r') as f:\n",
    "    labels_data = json.load(f)\n",
    "def airport_code_valid(code):\n",
    "    global labels_data\n",
    "    return str(code) in labels_data[\"i94port\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# UDF to check if the airport codes are valid\n",
    "udf_airport_code_valid = F.udf(airport_code_valid, T.BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#UDF to check if the state code is valid\n",
    "udf_valid_state_code = F.udf(lambda state: state != \"99\", T.BooleanType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Remove rows with null values in the most useful rows for our analysis\n",
    "- Remove duplicates row\n",
    "- Check that no invalid airport code exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration = df_immigration.dropna(how = \"any\", subset=[\"i94port\",\"cicid\",\"arrdate\",\"i94addr\"]) \\\n",
    "                                        .dropDuplicates() \\\n",
    "                                        .where(udf_airport_code_valid(F.col(\"i94port\")) \\\n",
    "                                               & udf_valid_state_code(F.col(\"i94addr\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Rows count after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38760226"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The data model use is a star schema, since the main desired output of the analysis is how the immigration flows change during the year, it is best to map the immigration movements in a fact table and all the information around them in dimension tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "To create this model we need to do the following:\n",
    "- Remove columns with a lot of invalid values or not useful for the scope or that contains private data\n",
    "- Rename columns if needed\n",
    "- Create a table for each desired dimension: cities, states, airports\n",
    "- Create the fact table: immigrations\n",
    "- Convert dates to timestamps\n",
    "- Store tables\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Polish immigration dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop CIC and not useful columns\n",
    "df_immigration = df_immigration.drop(\"entdepa\",\n",
    "                                     \"entdepd\",\n",
    "                                     \"entdepu\",\n",
    "                                     \"occup\",\n",
    "                                     \"insnum\",\n",
    "                                     \"admnum\",\n",
    "                                     \"dtadfile\",\n",
    "                                     \"visapost\",\n",
    "                                     \"dtaddto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_to_datetime(n):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(n))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "udf_convert_to_datetime = F.udf(convert_to_datetime, T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "udf_convert_matflag = F.udf(lambda x: x=='M', T.BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert dates into datetime\n",
    "df_immigration = df_immigration.withColumn(\"arrdate\", udf_convert_to_datetime(\"arrdate\")) \\\n",
    "            .withColumn(\"depdate\", udf_convert_to_datetime(\"depdate\"))\\\n",
    "            .withColumn(\"matflag\",udf_convert_matflag(\"matflag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename columns giving more meanings\n",
    "df_immigration = df_immigration.withColumnRenamed(\"cicid\",\"id\")\\\n",
    "                                .withColumnRenamed(\"i94yr\",\"i94year\")\\\n",
    "                                .withColumnRenamed(\"i94cit\",\"i94origin\")\\\n",
    "                                .withColumnRenamed(\"i94res\",\"i94residence\")\\\n",
    "                                .withColumnRenamed(\"i94port\",\"i94destination\")\\\n",
    "                                .withColumnRenamed(\"arrdate\",\"i94arrivaldate\")\\\n",
    "                                .withColumnRenamed(\"i94mode\",\"i94travelcode\")\\\n",
    "                                .withColumnRenamed(\"i94addr\",\"i94state\")\\\n",
    "                                .withColumnRenamed(\"depdate\",\"i94departuredate\")\\\n",
    "                                .withColumnRenamed(\"i94bir\",\"i94age\")\\\n",
    "                                .withColumnRenamed(\"matflag\",\"matchflag\")\\\n",
    "                                .withColumnRenamed(\"biryear\",\"i94birth\")\\\n",
    "                                .withColumnRenamed(\"fltno\",\"i94flightnumber\")\\\n",
    "                                .withColumnRenamed(\"i94mon\",\"i94month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- i94year: double (nullable = true)\n",
      " |-- i94origin: double (nullable = true)\n",
      " |-- i94residence: double (nullable = true)\n",
      " |-- i94destination: string (nullable = true)\n",
      " |-- i94arrivaldate: date (nullable = true)\n",
      " |-- i94travelcode: double (nullable = true)\n",
      " |-- i94state: string (nullable = true)\n",
      " |-- i94departuredate: date (nullable = true)\n",
      " |-- i94age: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- matchflag: boolean (nullable = true)\n",
      " |-- i94birth: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- i94flightnumber: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- i94month: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create dataframes for cities and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Drop not useful columns, rename columns better and remove duplicates\n",
    "df_cities = df_demographic.drop(\"Count\",\"Number of Veterans\",\"Average Household Size\")\\\n",
    "                    .withColumnRenamed(\"State Code\",\"State_Code\")\\\n",
    "                    .withColumnRenamed(\"Median Age\",\"Median_age\")\\\n",
    "                    .withColumnRenamed(\"Male Population\",\"Male_Population\")\\\n",
    "                    .withColumnRenamed(\"Female Population\",\"Female_Population\")\\\n",
    "                    .withColumnRenamed(\"Total Population\",\"Total_Population\")\\\n",
    "                    .withColumnRenamed(\"Foreign-born\",\"Foreign_born\")\\\n",
    "                    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create states from cities\n",
    "df_states = df_cities.select(\"State_Code\",\n",
    "                             \"State\")\\\n",
    "                    .withColumnRenamed(\"State_Code\",\"code\")\\\n",
    "                    .withColumnRenamed(\"State\",\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Drop duplicate column\n",
    "df_cities = df_cities.drop(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Median_age: double (nullable = true)\n",
      " |-- Male_Population: integer (nullable = true)\n",
      " |-- Female_Population: integer (nullable = true)\n",
      " |-- Total_Population: integer (nullable = true)\n",
      " |-- Foreign_born: integer (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_states.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create dataframe for airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- IATA: string (nullable = true)\n",
      " |-- ICAO: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Altitude: string (nullable = true)\n",
      " |-- Timezone: integer (nullable = true)\n",
      " |-- DST: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the not useful/duplicate columns\n",
    "different_usa_airports = df_immigration.select(F.col(\"i94destination\")).distinct()\n",
    "df_airports = df_airports.join(different_usa_airports ,df_airports.IATA==different_usa_airports.i94destination)\n",
    "df_airports = df_airports.drop(df_airports.i94destination)\\\n",
    "                        .dropDuplicates()\n",
    "df_airports.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Store immigration data using partions since the higher number of rows\n",
    "df_immigration.write.partitionBy(\"i94month\").parquet(\"pipeline_output/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# No partition needed for the other dataframes\n",
    "df_cities.write.parquet(\"pipeline_output/cities.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_states.write.parquet(\"pipeline_output/states.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airports.write.parquet(\"pipeline_output/airports.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load all the dataframes\n",
    "df_immigration = spark.read.parquet(\"pipeline_output/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_cities = spark.read.parquet(\"pipeline_output/cities.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_states = spark.read.parquet(\"pipeline_output/states.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airports = spark.read.parquet(\"pipeline_output/airports.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " Check that at least a row is imported in each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_not_empty(data, data_name):\n",
    "    if not df_airports.count() > 0:\n",
    "        raise ValueError(f\"{data_name} data is empty\") \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_not_empty(df_airports,\"Airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_not_empty(df_cities,\"Cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_not_empty(df_airports,\"States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_not_empty(df_immigration,\"Immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check that common keys exist between tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_common_keys(data_1, name_1, data_2, name_2, key_1,key_2):\n",
    "    if not data_1.join(data_2, getattr(data_1, key_1) == getattr(data_2, key_2)).count() > 0:\n",
    "            raise ValueError(f\"No common keys between {name_1} and {name_2}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_common_keys(df_airports,\"Airports\",df_immigration,\"Immigration\",\"IATA\",\"i94destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_common_keys(df_states,\"States\",df_immigration,\"Immigration\",\"code\",\"i94state\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_common_keys(df_cities,\"Cities\",df_immigration,\"Immigration\",\"State_Code\",\"i94state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "- Immigration\n",
    " | Field | Description | Source |\n",
    " | --- | --- | --- |\n",
    " | id: double PRIMARY KEY | primay key of the table | I94 Immigration Data\n",
    " | i94year: double | 4 digits year of the insert | I94 Immigration Data\n",
    " | i94origin: double | origin airport | I94 Immigration Data\n",
    " | i94residence: double | residence of the person | I94 Immigration Data\n",
    " | i94destination: string FOREIGN KEY | code of the destination | I94 Immigration Data\n",
    " | i94arrivaldate: date | arrival date of the person | I94 Immigration Data\n",
    " | i94travelcode: double |  how the person arrived1 = 'Air' 2 = 'Sea' 3 = 'Land' 9 = 'Not reported' | I94 Immigration Data\n",
    " | i94state: string FOREIGN KEY | code of the state | I94 Immigration Data\n",
    " | i94departuredate: date | date of departure | I94 Immigration Data\n",
    " | i94age: double | age of the person | I94 Immigration Data\n",
    " | i94visa: double | visa category   1 = Business 2 = Pleasure 3 = Student | I94 Immigration Data\n",
    " | count: double | number of person that applied for the given id | I94 Immigration Data\n",
    " | matchflag: boolean | Math of arrival and departure record | I94 Immigration Data\n",
    " | i94birth: double | year of birth of the person | I94 Immigration Data\n",
    " | gender: string | gender of the person | I94 Immigration Data\n",
    " | airline: string | airline of the travel | I94 Immigration Data\n",
    " | i94flightnumber: string | number of the flight I94 Immigration Data\n",
    " | visatype: string |  class of admission legally admitting the non-immigrant to temporarily stay in U.S. | I94 Immigration Data\n",
    " | i94month: double | month of the insertion | I94 Immigration Data\n",
    " \n",
    "- Cities\n",
    " \n",
    " | Field | Description | Source |\n",
    " | --- | --- | --- |\n",
    " | City: string | Name of the city | U.S. City Demographic Data |\n",
    " | Median_age: double | Median age of the people living in the city | U.S. City Demographic Data |\n",
    " | Male_Population: integer | Number of male in the city | U.S. City Demographic Data |\n",
    " | Female Population: integer | Number of female in the city | U.S. City Demographic Data |\n",
    " | Total Population: integer | Total population in the city | U.S. City Demographic Data |\n",
    " | Foreign_born: integer | Number of born foreigner in the city | U.S. City Demographic Data |\n",
    " | State_Code: string FOREIGN KEY | code of the state containing the city | U.S. City Demographic Data |\n",
    " | Race: string | Prevalent race of the city | U.S. City Demographic Data |\n",
    "\n",
    "- States\n",
    " \n",
    " | Field | Description | Source |\n",
    " | --- | --- | --- |\n",
    " | code: string PRIMARY KEY | Code of the state | U.S. City Demographic Data | \n",
    " | name: string | Name of the state | U.S. City Demographic Data |\n",
    " \n",
    " \n",
    "- Airports\n",
    " | Field | Description | Source |\n",
    " | --- | --- | --- |\n",
    " | Name: string | Name of airport | Airports |\n",
    " | City: string | Main city served by airport | Airports |\n",
    " | Country: string | Country or territory where airport is located | Airports |\n",
    " | IATA: string PRIMARY KEY | 3-letter IATA code | Airports |\n",
    " | ICAO: string | 4-letter ICAO code | Airports |\n",
    " | Latitude: double | Decimal degrees, usually to six significant digits. Negative is South, positive is North | Airports |\n",
    " | Longitude: double | Decimal degrees, usually to six significant digits. Negative is West, positive is East | Airports |\n",
    " | Altitude: integer | Altitude in feet | Airports |\n",
    " | Timezone: integer | Hours offset from UTC | Airports |\n",
    " | DST: string | Daylight savings time. One of E (Europe), A (US/Canada), S (South America), O (Australia), Z (New Zealand), N (None) or U (Unknown) | Airports |\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Query example\n",
    "\n",
    "Let's check if the pipeline executed correctly.\n",
    "Find the number of people travelling in the city of Atlanta in August 2016 and compare it with the number of foreigner living there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "atlanta_airport_code = df_airports.select(\"IATA\").where(F.col(\"City\")==\"Atlanta\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_immigrants = df_immigration.where((F.col(\"i94destination\") == atlanta_airport_code[0][\"IATA\"]) & \\\n",
    "                     (F.col(\"i94month\") == 8) & \\\n",
    "                    (F.col(\"i94year\") == 2016)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "foreign = df_cities.select(\"Foreign_born\").where(F.col(\"City\") == \"Atlanta\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4206959020489753"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_immigrants/foreign[0][\"Foreign_born\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The number of foreign born people in the city of Atlanta in August 2016 incremented about 3.4 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now let's answer some questions about the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Choice of tools and technologies for the project.\n",
    "\n",
    "The main technology used in this project is Apache Spark, that is very useful to process and analyze a big quantity of data with easy scalability. Since we had to merge and transform the data before using it it's the perfect choice for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- How often the data should be updated and why\n",
    "\n",
    "The data should be updated monthly/yearly to be able to capture the trends between the years and discover patters between the months. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- What if the data was increased by 100x.\n",
    "\n",
    "If the data increased 100x a bigger spark cluster is needed, with more workers and so bigger processing data. The easiest way to achieve this is to use AWS S3 and EMR. Also a finer parquet division would help (i.e by day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- What if the data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "We need to schedule the execution of the pipeline, with a tool like Airflow, making sure that the SLA (Service Level Agreement) is configured for that time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- What if the database needed to be accessed by 100+ people.\n",
    "\n",
    "We need to configure Apache Spark to enable concurrent access of the team.\n",
    "If data is stored into a database, make sure that it supports atomic operations.\n",
    "We can use AWS Redshift that support virtually unlimited concurrent users and concurrent queries based on the number of cluster or Spark Hive by setting concurrency values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
